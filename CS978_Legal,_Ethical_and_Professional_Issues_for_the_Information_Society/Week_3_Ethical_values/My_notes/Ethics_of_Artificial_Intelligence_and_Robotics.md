# Ethics of Artificial Intelligence and Robotics

***TO FINISH***

These notes are based on entry in the Stanford Encyclopedia of Philosophy: [Ethics of Artificial Intelligence and Robotics](https://plato.stanford.edu/entries/ethics-ai/#PrivSurv). Consult with these notes.

## Main Debates

### Ethical issues that arise with AI systems as *objects*

#### Privacy & Surveillance

1. ***Overview of Privacy and Surveillance in Information Technology***
    * **Aspects of Privacy:**
        * Privacy includes various dimensions such as (Bennett and Raab 2006):
            * "the right to be alone"
            * information privacy
            * Privacy as an aspect of personhood
            * Control over information about oneself
            * The right to secrecy
    * **Evolution of Surveillance:**
        * Privacy studies have historically focused on state surveillance by secret services
        * Now include surveillance by other state agents, businesses, and even individuals.
    * **Regulatory Lag:**
        * Technological advancements have outpaced regulations.
        * Regulation (EU) 2016/679 (General Data Protection Regulation or GDPR) exists but enforcement is challenging.
        * Resulting in a form of anarchy exploited by powerful entities, sometimes in plain sight, sometimes in hiding.
1. ***Expansion of the Digital Sphere and Data Collection***
    * **Digital Integration:**
        * All data collection and storage are now digital.
        * Our lives are increasingly connected to a single Internet.
        * More and more sensor technology in use to generate data about non-digital aspects of our lives.
    * **Role of AI:**
        * AI enhances capabilities for intelligent data collection and data analysis.
        * Affects both mass surveillance and targeted surveillance.
    * **Data Trading:**
        * Personal data is often traded between agents for a fee.
1. ***Challenges in Controlling Data Collection and Access***
    * **Difficulty in Oversight:**
        * Harder to control who collects data and who has access compared to the analogue era.
    * **Amplification by AI Technologies:**
        * Facial Recognition:
            * Enables identification, profiling, and tracking of individuals (Whittaker et al. 2018).
        * Device Fingerprinting:
            * Identifies devices based on unique configurations.
    * **Privacy Erosion:**
        * Creates a comprehensive profile of individuals without their full awareness (Smolan 2016).
        * Arguably a scandal that still has not received public attention.
1. ***Data Collection Practices of Major Tech Companies***
    * **"Big 5" Companies:**
        * Amazon, Google/Alphabet, Microsoft, Apple, Facebook.
    * **Business Model Based on:**
        * Deception and manipulation.
        * Exploiting human weaknesses such as addiction and procrastination (Harris 2016).
    * **Surveillance Economy:**
        * Internet business models focus on gaining and retaining user attention to collect data.
        * Termed "surveillance capitalism" (Zuboff 2019).
    * **Loss of Autonomy and Control:**
        * Users have lost ownership and control over their personal data.
        * Attempts to escape this model are difficult without compromising modern life and work.
1. ***AI's Deep Understanding and Manipulation of Individuals***
    * **Insights Beyond Self-Knowledge:**
        * AI systems can reveal personal facts users may wish to suppress or are unaware of.
    * **Mental State Analysis:**
        * Observing online behavior allows insights into out mental states (Burr and Cristianini 2019) and manipulation.
    * **Derived Data Concerns:**
        * Calls for protection of "derived data", which is data inferred from user behavior (Wachter and Mittelstadt 2019).
    * **Future Implications:**
        * Yuval Noah Harari's Question: "What will happen to society, politics and daily life when non-conscious but highly intelligent algorithms know us better than we know ourselves?" (Harari 2016: 462)

6. Emergence of Smart Technologies and Further Data Gathering
Internet of Things (IoT):
Proliferation of connected devices (smartphones, TVs, appliances).
Smart Systems:
Smart homes, smart cities, and smart governance contribute to extensive data collection.
Real-Time Data Collection:
Offers more detailed, diverse, and real-time information about individuals.
7. Privacy-Preserving Techniques
Methods to Protect Privacy:
Anonymization: Removing personally identifiable information.
Access Control and Encryption: Restricting data access and securing data.
Differential Privacy:
Adding calibrated noise to data outputs to protect individual privacy (Dwork et al. 2006; Abowd 2017).
Challenges:
Implementing these techniques requires additional effort and cost.
Competitive Advantage:
Some companies leverage better privacy practices as a selling point.
8. Difficulties in Enforcing Privacy Regulations
Enforcement Barriers:
Identifying Responsible Parties: Difficult to pinpoint legal entities responsible for data misuse.
Proving Violations: Requires evidence of actions and potentially intent.
Jurisdictional Challenges: Finding a competent court and enforcing decisions.
Lack of Legal Protections:
Consumer rights and product liability laws are often missing or hard to enforce for digital products.
Corporate Practices:
Companies may test products on consumers without liability concerns.
Strongly defend their intellectual property rights.
Internet Libertarianism:
The belief that technical solutions will inherently resolve societal problems (Mozorov 2013).
Often leads to under-regulation and reliance on market forces.
9. Conclusion
Erosion of Privacy:
The convergence of AI, IoT, and digital technologies has led to significant privacy challenges.
Need for Attention and Action:
The current state is seen as a scandal needing public awareness and regulatory action.
Balancing Innovation and Privacy:
While technological advances offer benefits, there is a critical need to protect individual privacy rights.
Empowering Individuals:
Emphasis on regaining control and ownership over personal data.


At the same time, controlling who collects which data, and who has access, is much harder in the digital world than it was in the analogue world of paper and telephone calls. Many new AI technologies amplify the known issues. For example, face recognition in photos and videos allows identification and thus profiling and searching for individuals (Whittaker et al. 2018: 15ff). This continues using other techniques for identification, e.g., “device fingerprinting”, which are commonplace on the Internet (sometimes revealed in the “privacy policy”). The result is that “In this vast ocean of data, there is a frighteningly complete picture of us” (Smolan 2016: 1:01). The result is arguably a scandal that still has not received due public attention.

The data trail we leave behind is how our “free” services are paid for—but we are not told about that data collection and the value of this new raw material, and we are manipulated into leaving ever more such data. For the “big 5” companies (Amazon, Google/Alphabet, Microsoft, Apple, Facebook), the main data-collection part of their business appears to be based on deception, exploiting human weaknesses, furthering procrastination, generating addiction, and manipulation (Harris 2016 [OIR]). The primary focus of social media, gaming, and most of the Internet in this “surveillance economy” is to gain, maintain, and direct attention—and thus data supply. “Surveillance is the business model of the Internet” (Schneier 2015). This surveillance and attention economy is sometimes called “surveillance capitalism” (Zuboff 2019). It has caused many attempts to escape from the grasp of these corporations, e.g., in exercises of “minimalism” (Newport 2019), sometimes through the open source movement, but it appears that present-day citizens have lost the degree of autonomy needed to escape while fully continuing with their life and work. We have lost ownership of our data, if “ownership” is the right relation here. Arguably, we have lost control of our data.

These systems will often reveal facts about us that we ourselves wish to suppress or are not aware of: they know more about us than we know ourselves. Even just observing online behaviour allows insights into our mental states (Burr and Christianini 2019) and manipulation (see below section 2.2). This has led to calls for the protection of “derived data” (Wachter and Mittelstadt 2019). With the last sentence of his bestselling book, Homo Deus, Harari asks about the long-term consequences of AI:

What will happen to society, politics and daily life when non-conscious but highly intelligent algorithms know us better than we know ourselves? (2016: 462)

Robotic devices have not yet played a major role in this area, except for security patrolling, but this will change once they are more common outside of industry environments. Together with the “Internet of things”, the so-called “smart” systems (phone, TV, oven, lamp, virtual assistant, home,…), “smart city” (Sennett 2018), and “smart governance”, they are set to become part of the data-gathering machinery that offers more detailed data, of different types, in real time, with ever more information.

Privacy-preserving techniques that can largely conceal the identity of persons or groups are now a standard staple in data science; they include (relative) anonymisation , access control (plus encryption), and other models where computation is carried out with fully or partially encrypted input data (Stahl and Wright 2018); in the case of “differential privacy”, this is done by adding calibrated noise to encrypt the output of queries (Dwork et al. 2006; Abowd 2017). While requiring more effort and cost, such techniques can avoid many of the privacy issues. Some companies have also seen better privacy as a competitive advantage that can be leveraged and sold at a price.

One of the major practical difficulties is to actually enforce regulation, both on the level of the state and on the level of the individual who has a claim. They must identify the responsible legal entity, prove the action, perhaps prove intent, find a court that declares itself competent … and eventually get the court to actually enforce its decision. Well-established legal protection of rights such as consumer rights, product liability, and other civil liability or protection of intellectual property rights is often missing in digital products, or hard to enforce. This means that companies with a “digital” background are used to testing their products on the consumers without fear of liability while heavily defending their intellectual property rights. This “Internet Libertarianism” is sometimes taken to assume that technical solutions will take care of societal problems by themselves 